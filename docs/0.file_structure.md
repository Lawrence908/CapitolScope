CapitolScope/
│
├── data/                        # Raw and processed data storage
│   ├── raw/                     # Raw data files from APIs and Congress pipeline
│   ├── processed/               # Processed data with feature engineering applied
│   ├── logs/                    # Logs for data ingestion and processing
│   └── README.md                # Documentation for data directory
│
├── src/                         # Core source code
│   ├── ingestion/               # Data ingestion scripts
│   │   ├── fetch_stock_data.py  # Scripts to pull stock data from AlphaVantage/yFinance
│   │   ├── fetch_congress_data.py # Scripts for Congress data ingestion
│   │   └── __init__.py
│   │
│   ├── processing/              # Data cleaning and feature engineering
│   │   ├── compute_indicators.py # Functions for technical indicators (e.g., RSI, MACD)
│   │   ├── preprocess_congress.py # Cleaning and normalizing Congress data
│   │   └── __init__.py
│   │
│   ├── modeling/                # Machine learning models
│   │   ├── train_sklearn.py     # Training Scikit-learn models (MVP)
│   │   ├── train_tensorflow.py  # TensorFlow model training (upgrade)
│   │   ├── backtesting.py       # Backtesting scripts
│   │   └── __init__.py
│   │
│   ├── deployment/              # Deployment and API endpoints
│   │   ├── api.py               # REST API for model predictions
│   │   ├── aws_setup.py         # AWS configuration and deployment scripts
│   │   └── __init__.py
│   │
│   ├── utils/                   # Utility functions shared across modules
│   │   ├── db_utils.py          # Database connections and queries
│   │   ├── logger.py            # Logging utilities
│   │   ├── config.py            # Configuration settings (e.g., API keys, DB URIs)
│   │   └── __init__.py
│   │
│   └── __init__.py
│
├── notebooks/                   # Jupyter notebooks for experimentation
│   ├── data_exploration.ipynb   # Exploratory data analysis
│   ├── feature_engineering.ipynb # Prototyping features
│   └── model_prototyping.ipynb  # Initial model experiments
│
├── tests/                       # Automated tests
│   ├── unit/                    # Unit tests for individual modules
│   ├── integration/             # Integration tests for pipelines and models
│   └── README.md                # Test suite documentation
│
├── requirements.txt             # Python dependencies
├── setup.py                     # Package configuration
├── README.md                    # Project documentation
└── .gitignore                   # Ignored files (e.g., API keys, data files)


### **Explanation of Key Components**

#### **1. `data/`**
- Stores raw, processed, and log files.
- Keeps data files outside the main source code to ensure separation of concerns.
- Logs are stored here to track API issues and processing steps.

#### **2. `src/`**
This is the core application code:
- **`ingestion/`**: Handles all data-fetching tasks (e.g., calling APIs, scraping Congress trades).
- **`processing/`**: Contains functions for cleaning, normalizing, and engineering features.
- **`modeling/`**: Responsible for training and backtesting machine learning models.
- **`deployment/`**: Includes REST APIs for predictions and deployment configurations (AWS scripts).
- **`utils/`**: Contains helper functions for logging, database connections, and configuration.

#### **3. `notebooks/`**
- A sandbox for experimentation, such as exploring data, testing new features, or prototyping models.
- Notebooks are for development purposes only, not production use.

#### **4. `tests/`**
- Automated test suite for maintaining system integrity.
  - **Unit Tests**: Test individual functions or classes.
  - **Integration Tests**: Validate that the entire pipeline works together seamlessly.

#### **5. Configuration Files**
- **`requirements.txt`**: Lists Python dependencies for easy setup.
- **`setup.py`**: Enables packaging and distribution of the project if needed.
- **`.gitignore`**: Ensures sensitive files (e.g., API keys, local data files) are not committed to the repository.

---

### **How the Structure Scales**
1. **MVP Phase**: Start with `ingestion/`, `processing/`, and `modeling/` using Scikit-learn.
2. **TensorFlow Upgrade**: Add `train_tensorflow.py` in `modeling/` and extend `utils/` for GPU configuration.
3. **Deployment Phase**: Develop APIs in `deployment/` to expose prediction capabilities and integrate with AWS.